# ğŸš€ Guide dâ€™exÃ©cution â€” RESCUE STREAM (Windows + WSL)

Ce document explique Ã©tape par Ã©tape comment lancer **RESCUE STREAM** sur un environnement **Windows (Kafka + scripts Python)** et **WSL/Ubuntu (Airflow)**.

> âœ… Objectif : gÃ©nÃ©rer les flux temps rÃ©el (Kafka), produire les CSV, puis exÃ©cuter les traitements orchestrÃ©s (Airflow).

---

## PrÃ©-requis

### Windows
- Java installÃ© (JDK recommandÃ©)
- Kafka installÃ© (ex: `C:\kafka\kafka_2.13-3.6.0`)
- Python 3.x installÃ©
- `pip` fonctionnel

### WSL (Ubuntu)
- Airflow installÃ© dans un environnement virtuel
- AccÃ¨s au projet via `/mnt/c/...`

---

## ğŸ§¹ 0) Nettoyer les logs Kafka (Windows)

Avant de relancer Kafka, il est recommandÃ© de nettoyer les dossiers de logs :

```powershell
Get-ChildItem C:\tmp

Remove-Item -Recurse -Force C:\tmp\kafka-logs
Remove-Item -Recurse -Force C:\tmp\zookeeper

dir C:\tmp
````

---

## ğŸŸ¦ 1) DÃ©marrer Zookeeper (Windows)

Ouvre **une premiÃ¨re fenÃªtre PowerShell** :

```powershell
cd C:\kafka\kafka_2.13-3.6.0
.\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties
```

## ğŸŸ© 2) DÃ©marrer Kafka Broker (Windows)

Ouvre **une deuxiÃ¨me fenÃªtre PowerShell** :

```powershell
cd C:\kafka\kafka_2.13-3.6.0
.\bin\windows\kafka-server-start.bat .\config\server.properties
```

## ğŸš‘ 3) Lancer les Producers (Windows)

Dans un terminal PowerShell :

```powershell
cd C:\Users\pc\Projects\Urgences\bigdata

python create_force_ambulances.py
python .\producers\producer_hopitaux.py
python .\producers\producer_appels.py
python .\producers\producer_ambulances.py
```

## ğŸ§  4) Lancer le service Dispatch (Windows)

```powershell
cd C:\Users\pc\Projects\Urgences\bigdata
python -m services.service_dispatch
```

---

## ğŸ“¥ 5) Lancer les Consumers (Windows)

Dans un terminal PowerShell :

```powershell
cd C:\Users\pc\Projects\Urgences\bigdata

python .\consumers\consumer_hopitaux_to_csv.py
python .\consumers\consumer_appels_to_csv.py
python .\consumers\consumer_ambulances_to_csv.py
python .\consumers\consumer_dispatch_to_csv.py

python prepare_structured_dispatch.py
```

## ğŸŒ¬ 6) Lancer Airflow (WSL/Ubuntu)

Ouvre WSL / Ubuntu.

### ğŸŸ§ 6.1 Activer lâ€™environnement virtuel

```bash
cd /mnt/c/Users/pc/Projects/Urgences/bigdata
source ~/airflow/venv/bin/activate
```

---

### ğŸŸ¦ 6.2 DÃ©marrer le Scheduler

```bash
airflow scheduler
```

---

### ğŸŸ© 6.3 DÃ©marrer le Webserver

Dans un **second terminal WSL** :

```bash
airflow webserver
```

Puis ouvre :

ğŸ‘‰ [http://localhost:8080](http://localhost:8080)

---

## ğŸ” 7) DÃ©clencher les DAGs (optionnel)

Toujours dans WSL :

```bash
airflow dags trigger bigdata_prepare_hopitaux_dag
airflow dags trigger bigdata_prepare_appels_dag
airflow dags trigger bigdata_prepare_dispatch_dag
```

---

> ğŸš‘ **Un flux, une dÃ©cision, une vie sauvÃ©e.**


